{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from scripts.voc_tools.voc_tools import visualize, return_files_in_directory, generate_mask_from_box, create_dataset,get_bounding_boxes, export_dataset, import_dataset\n",
    "from tifffile import imread\n",
    "\n",
    "def span_columns(max_x, max_y):\n",
    "    cols = torch.zeros([max_y, max_x])\n",
    "    for i in range(max_x):\n",
    "        cols[:,i] = (i+1)\n",
    "    return cols\n",
    "\n",
    "def span_rows(max_x, max_y):\n",
    "    rows = torch.zeros([max_y, max_x])\n",
    "    for i in range(max_y):\n",
    "        rows[i,:] = (i+1)\n",
    "    return rows\n",
    "\n",
    "def get_bbox_coordinates_one_box(tensor): \n",
    "    all_x, all_y = (tensor.squeeze() == 1).nonzero(as_tuple=True)\n",
    "    smallest_x, smallest_y = torch.min(all_x).item(), torch.min(all_y).item()\n",
    "    largest_x, largest_y = torch.max(all_x).item(), torch.max(all_y).item()\n",
    "    return (smallest_y, smallest_x), (largest_y, largest_x)\n",
    "\n",
    "def get_min_max_x(unique_tensor):\n",
    "    unique_tensor = unique_tensor[unique_tensor!= 0]\n",
    "    min_xs = []\n",
    "    min_xs.append(unique_tensor[0].item())\n",
    "    max_xs = []\n",
    "    spotted_more_than_one_box = False\n",
    "    for i in range(len(unique_tensor)):\n",
    "        next_idx = (i+1)\n",
    "        if next_idx <= (len(unique_tensor) -1):\n",
    "            next_element = unique_tensor[next_idx]\n",
    "            current_element = unique_tensor[i]\n",
    "            diff = next_element - current_element\n",
    "            if diff > 1:\n",
    "                spotted_more_than_one_box = True\n",
    "                min_xs.append(next_element.item())\n",
    "                max_xs.append(current_element.item())\n",
    "        else:\n",
    "            current_element = unique_tensor[i]\n",
    "            max_xs.append(current_element.item())\n",
    "    return min_xs, max_xs, spotted_more_than_one_box\n",
    "\n",
    "\n",
    "\n",
    "def get_min_max_y(base_tensor, min_xs, max_xs):\n",
    "    ys = base_tensor[1]\n",
    "    min_ys, max_ys = [], []\n",
    "    # Slice tensor and extract values\n",
    "    for idx, i in enumerate(min_xs):\n",
    "        # slice colum wise\n",
    "        start = int(i-1)\n",
    "        end = int(max_xs[idx])\n",
    "        slice = ys[:,start:end]\n",
    "        # get unique values\n",
    "        unique_tensor = torch.unique(slice)\n",
    "        unique_tensor = unique_tensor[unique_tensor!= 0]\n",
    "        min_ys.append(unique_tensor[0].item())\n",
    "        for i in range(len(unique_tensor)):\n",
    "                next_idx = (i+1)\n",
    "                if next_idx <= (len(unique_tensor) -1):\n",
    "                    next_element = unique_tensor[next_idx]\n",
    "                    current_element = unique_tensor[i]\n",
    "                    diff = next_element - current_element\n",
    "                    if diff > 1:\n",
    "                        min_ys.append(next_element.item())\n",
    "                        max_ys.append(current_element.item())\n",
    "                else:\n",
    "                    current_element = unique_tensor[i]\n",
    "                    max_ys.append(current_element.item())\n",
    "    return min_ys, max_ys\n",
    "    \n",
    "\n",
    "def get_bbox_coordinates(tensor):\n",
    "    # get base\n",
    "    n_rows = tensor.shape[0]\n",
    "    n_cols = tensor.shape[1]\n",
    "    cols = span_columns(n_cols, n_rows)\n",
    "    rows = span_rows(n_cols, n_rows)\n",
    "    base = torch.zeros([2, n_rows, n_cols])\n",
    "    base[0,:,:] = cols\n",
    "    base[1,:,:] = rows\n",
    "    res = tensor * base\n",
    "    min_xs, max_xs, spotted_more_than_one_box = get_min_max_x(torch.unique(res[0]))\n",
    "    if spotted_more_than_one_box == True:\n",
    "        min_ys, max_ys  = get_min_max_y(res, min_xs, max_xs)\n",
    "        # build min\n",
    "        if len(min_xs) < len(min_ys):\n",
    "            min_xs = [min_xs[-1] for i in range(len(min_ys))]\n",
    "            max_xs = [max_xs[-1] for i in range(len(min_ys))]\n",
    "        if len(min_ys) < len(min_xs):\n",
    "            min_ys = [min_ys[-1] for i in range(len(min_xs))]\n",
    "            max_ys = [max_ys[-1] for i in range(len(min_xs))]\n",
    "        coord = [((min_xs[i], min_ys[i]), (max_xs[i], max_ys[i])) for i in range(len(min_xs))]\n",
    "        return coord, spotted_more_than_one_box\n",
    "    else:\n",
    "        return get_bbox_coordinates_one_box(tensor), spotted_more_than_one_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 77\n",
    "img = torch.Tensor(imread(f\"./data/CVC-ClinicDB-1/Ground Truth/{idx}.tif\")).long()\n",
    "visualize(img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_many_classes = [71, 545, 546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in image_with_many_classes:\n",
    "#     path = f\"/Users/michaelgroeger/workspace/FEA_Internship/boxshrink/medical_ai_challenge/data/CVC-ClinicDB-1/Original/{i}.tif\"\n",
    "#     img = Image.fromarray(imread(path), mode=\"RGB\")\n",
    "#     output_path_mask = path.replace(\"Original\", \"multiple_findings\").replace(\"tif\", \"png\")\n",
    "#     img.save(output_path_mask, quality=100, subsampling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_coordinates_one_box(tensor): \n",
    "    all_x, all_y = (tensor.squeeze() == 1).nonzero(as_tuple=True)\n",
    "    smallest_x, smallest_y = torch.min(all_x).item(), torch.min(all_y).item()\n",
    "    largest_x, largest_y = torch.max(all_x).item(), torch.max(all_y).item()\n",
    "    return (smallest_x, smallest_y), (largest_x, largest_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Function to generate masks from bounding boxes\n",
    "def generate_mask_from_box_colonoscopy(\n",
    "    image,\n",
    "    smallest,\n",
    "    largest,\n",
    "):\n",
    "    \"\"\"Function to generate the box-like segmentation masks to be used uring training\n",
    "\n",
    "    Args:\n",
    "        dataset (csv): csv holding path to each considered xml file\n",
    "        category_data (csv): csv: index,category,red,green,blue -> 1,person,192,128,128\n",
    "        output_path (string): where to put the masks\n",
    "    \"\"\"\n",
    "    image_width, image_height = image.shape[2], image.shape[1]\n",
    "    # Create mask\n",
    "    mask = np.zeros([image_height, image_width], dtype=np.uint8)\n",
    "    # Get all boxes present on the image\n",
    "    # get coordinates\n",
    "    ymin, xmin, ymax, xmax = (\n",
    "        smallest[1], smallest[0], largest[1], largest[0]\n",
    "    )\n",
    "    # Python does array[inclusive:exclusive] therefore we need to add + 1 to the max values\n",
    "    # But then we also need to catch the case that the +1 will be out of the image\n",
    "    if ymax != image_height:\n",
    "        ymax = ymax + 1\n",
    "    if xmax != image_width:\n",
    "        xmax = xmax + 1\n",
    "    mask[xmin:xmax, ymin:ymax] = 1\n",
    "    mask = Image.fromarray(np.uint8(mask * 255) , 'L')\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pngs = return_files_in_directory(\"./data/CVC-ClinicDB-1/multiple_findings/colonoscopy-multiple-findings\", \".png\")\n",
    "for png in pngs:\n",
    "    img = Image.open(png).convert('L')\n",
    "    name = png.split('/')[-1]\n",
    "    img.save(f\"./data/CVC-ClinicDB-1/multiple_findings/colonoscopy-multiple-findings/grayscale/{name}\", quality=100, subsampling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_all_bboxes(mask_dir, box_dir):\n",
    "    # get all masks from dir\n",
    "    files = return_files_in_directory(mask_dir, ending=\".tif\")\n",
    "    for idx, mask_path in tqdm(enumerate(files), desc=\"Creating Boxes from masks\"):\n",
    "        # load image\n",
    "        image = Image.open(mask_path)\n",
    "        image = ToTensor()(image)\n",
    "        # map all positive values to 1\n",
    "        image[image>0] = 1.0\n",
    "        # get box coordinates\n",
    "        smallest, largest = get_bbox_coordinates(image)\n",
    "        # infer mask\n",
    "        bb_mask = generate_mask_from_box_colonoscopy(image=image, smallest=smallest, largest=largest)\n",
    "        # save mask to new dir\n",
    "        output_path_mask = (\n",
    "            box_dir + \"/\" + mask_path.split('/')[-1]\n",
    "        ).replace(\"tif\", \"png\")\n",
    "        bb_mask.save(output_path_mask, quality=100, subsampling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 351\n",
    "\n",
    "image = Image.open(f\"./data/CVC-ClinicDB-1/Ground Truth/{idx}.tif\")\n",
    "image = ToTensor()(image)\n",
    "visualize(img=image.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = \"./data/CVC-ClinicDB-1/multiple_findings/colonoscopy-multiple-findings\"\n",
    "category_path = \"./data/CVC-ClinicDB-1/multiple_findings/colonoscopy-multiple-findings/color_codes.csv\"\n",
    "xmls = return_files_in_directory(xml_path, ending='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating dataset: 100%|██████████| 30/30 [00:00<00:00, 423.30it/s]\n"
     ]
    }
   ],
   "source": [
    "ds = create_dataset(xmls, \"name\", condition=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dataset(ds[0], \"./data/CVC-ClinicDB-1/multiple_findings/colonoscopy-multiple-findings/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Masks: 100%|██████████| 30/30 [00:00<00:00, 38.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dsi = import_dataset(\"./data/CVC-ClinicDB-1/multiple_findings/colonoscopy-multiple-findings/dataset.csv\")\n",
    "generate_mask_from_box(dsi, category_path, \"./data/CVC-ClinicDB-1/multiple_findings/colonoscopy-multiple-findings\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c46e6bf4e9d1e0cccc1750c14946f2a66e9455538981af60f616bc3d6968a798"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('3.7.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
